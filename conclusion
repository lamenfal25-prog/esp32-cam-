El desarrollo de este laboratorio permitió comprender de manera práctica la integración entre hardware y software en sistemas de reconocimiento de objetos aplicados al Internet de las Cosas (IoT). Mediante el uso de la ESPCAM, la plataforma Edge Impulse y un display OLED, se logró implementar un prototipo funcional capaz de identificar objetos en tiempo real, mostrando los resultados mediante etiquetas visuales y activación de LEDs.
Durante el proceso, se reforzaron los conocimientos sobre la configuración del entorno Arduino IDE, la instalación de controladores y librerías, y la programación del microcontrolador ESP32-CAM. Además, se aplicaron los procedimientos vistos en los temas 2 y 3 del curso, relacionados con las configuraciones básicas de hardware, comunicación serial e integración de modelos de inteligencia artificial en dispositivos embebidos.
Uno de los principales aprendizajes fue comprobar que la visión artificial puede ejecutarse de forma local en un dispositivo pequeño y de bajo costo, sin requerir conexión permanente a Internet. Este tipo de soluciones representa un avance significativo en el campo del Edge Computing, ya que permite que la inteligencia artificial funcione directamente en el hardware, optimizando tiempo de respuesta y consumo de energía.
Se observó que la calidad del reconocimiento depende de diversos factores, como la iluminación del entorno, la distancia entre la cámara y el objeto, y la nitidez de la imagen. Durante las pruebas, al ajustar la iluminación y mejorar el enfoque, la precisión del sistema aumentó notablemente. Esto evidenció la importancia de la calibración y la preparación previa de los datos para garantizar un funcionamiento estable y confiable.
El laboratorio también fortaleció habilidades de trabajo en equipo, solución de problemas y documentación técnica. Ambas integrantes colaboraron en distintas etapas del desarrollo, lo cual permitió completar el proyecto de forma eficiente y con una comprensión integral del sistema.

Cómo mejoraríamos el proyecto en trabajos futuros
Para mejorar este prototipo en futuras versiones, se podrían implementar las siguientes acciones:
1.	Capturar más imágenes con diferentes ángulos, fondos e iluminación para aumentar la precisión del modelo de reconocimiento.
2.	Utilizar un soporte fijo para evitar vibraciones y mejorar la nitidez durante la inferencia.
3.	agregar más salidas visuales o sonoras 
